# VehicleTracking100
https://drive.google.com/drive/folders/1lHnZzNADGUyABK5rEJSOb1gEGd-lxgcp?usp=share_link
VehicleTracking100 is a vehicle target tracking dataset that we have built specifically for algorithms of the type of joint detection and appearance feature extraction. Typically, tracking datasets in driving scenarios annotate the identity of targets from multiple classes. For individual vehicle classes, the identity ids are not continuous and tedious manual processing is often required in order to train the class individually, which makes it difficult to carry out research and improve the suitability of the algorithm for the particular class. Specifically, we used the experimental vehicle's front-facing camera to capture video at 25 frames per second in typical scenarios such as elevated, rural roads, CBD, and intersections. One frame was extracted and annotated every five frames. The annotation format is based on the KITTI dataset, and each video is saved with between 80 and 120 consecutive images, with a total of 100 segments, of which 70 are used for training and 30 for evaluation. We label cars, SUVs, vans, etc. as a unified vehicle category. For tagging, we begin at 0 and assign a unique id to each vehicle in the sequence. For the target position, we set (x/W_img,y/H_img,w/W_img,h〖/H〗_img), where x and y are the coordinates of the center point of the bounding box, w and h are the width and height of the bounding box, Wimg and Himg correspond to the width and height of the image. Fig. 8 shows some pie charts of the distribution of the dataset according to the different metrics. Among them, (a) shows the distribution of scenes in the dataset. There are 52 city road scenes in the sequence of 100 tracking segments, which is the main scenario occurring in real driving environment and is characterized by high uncertainty of vehicle movement and a wide variety and number of traffic participants. In addition to the urban road scenes, we created 19 rural road scenes, 6 elevated road scenes and 9 low light scenes at night. In particular, we selected intersections, tunnels and narrow roads to create 14 special road scenes to test the algorithm's ability to track targets under more demanding driving scenarios. (b) shows the distribution of vehicles of different sizes on the pixel layer. We set targets smaller than 32*32 pixels as small targets, those with pixel sizes between 32*32 and 96*96 as medium targets, and those larger than 96*96 pixels as large targets. In the end, there are 10225 small targets, 18363 medium targets and 13836 large targets.(c) shows the statistics of the congestion in the scene in the tracking sequence. We calculate the average number of vehicle targets per frame in a single video sequence, and count sequences with less than 4 vehicles as sparse sequences, 21 in total, sequences with more than 4 to 10 vehicles per frame as normal sequences, 58 in total, and sequences with more than 10 vehicles per frame as crowded sequences, 21 in total.
